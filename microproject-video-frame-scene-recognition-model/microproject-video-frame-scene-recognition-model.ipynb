{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h1 style=\"text-align: center\">\n","<div style=\"color: #DD3403; font-size: 60%\">Data Science DISCOVERY MicroProject</div>\n","<span style=\"\">MicroProject: Building a Scene Recognition Model form Video Frames</span>\n","<div style=\"font-size: 60%;\"><a href=\"https://discovery.cs.illinois.edu/microproject/video-frame-scene-recognition-model/\">https://discovery.cs.illinois.edu/microproject/video-frame-scene-recognition-model/</a></div>\n","</h1>\n","\n","<hr style=\"color: #DD3403;\">"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Data Source: Frames of a Video\n","\n","Visual images are an important part of all media and Data Scientists are often using images as data sources.  In this MicroProject, you will create a simple model to detect the amount of time spent in two different \"scenes\" we used when creating office-hour style videos for Data Science DISCOVERY.  To do this, you will learn how to import an entire folder of images, preform image analysis, and create your own model without using a pre-build library.  Let's nerd out! :)\n","\n","> *This MicroProject was inspired by a podcast that we recently recorded with the team from the Center for Innovation in Teaching and Learning who helped produce our video.  To learn the background and hear from Karle and Wade about the journey of creating DISCOVERY, go over and listen to our episode on the \"Teach Talk Listen Learn Podcast\" where talk with TTLL host Bob Dignan and our CITL video producer Eric Schumacher: https://citl.illinois.edu/citl-101/teaching-learning/teach-talk-listen-learn*\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Loading Video Frames\n","\n","We have provided you with one frame every second from our video [*\"Outliers Impact on Correlation (m6-02b)\"*](https://www.youtube.com/watch?v=bd6hQ2UcIJc) that is used as part of our [DISCOVERY lecture covering Correlation](https://discovery.cs.illinois.edu/learn/Towards-Machine-Learning/Correlation/).  Each of these frames are in the `frames` sub-folder.\n","\n","The `skimage` library is commonly used to load image data into Python.  Specifically:\n","\n","- The full function name we will be using is `skimage.io.imread(filename)`.  This function will read a filename and return the pixel color for every pixel in the image.\n","\n","- To use the `imread` function, you will need to either do one of the following:\n","\n","    1. Import the entire `skimage` library by using the import line: `import skimage`.  After importing all of `skimage`, you will call the function using it's fully qualified name: `skimage.io.imread(filename)`.\n","    \n","    **ALTERATIVELY**\n","    \n","    2. Import only the `imread` function by using the more specific import line: `from sklearn.io import imread`.  After importing only `imread`, you will call the function directly: `imread(filename)`\n","\n","    *(People's preference differs on how they prefer to import and use libraries.  Both techniques work! :))*\n","\n","### Read Pixel Data for `frames/frame_0001.jpg`\n","\n","As noted earlier, we have provided a `frames` directory with all of the frames.\n","\n","In the following cell, store the pixel color data from the file named `frames/frame_0001.jpg` image in the variable `pixels` by using the `imread` function:\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["array([[[ 91,  83,  80],\n","        [ 91,  83,  80],\n","        [ 91,  83,  80],\n","        ...,\n","        [ 75,  72,  79],\n","        [ 80,  78,  83],\n","        [ 83,  81,  86]],\n","\n","       [[ 91,  83,  80],\n","        [ 91,  83,  80],\n","        [ 91,  83,  80],\n","        ...,\n","        [ 73,  70,  77],\n","        [ 79,  77,  82],\n","        [ 83,  81,  86]],\n","\n","       [[ 91,  83,  80],\n","        [ 91,  83,  80],\n","        [ 91,  83,  80],\n","        ...,\n","        [ 69,  66,  73],\n","        [ 77,  75,  80],\n","        [ 83,  81,  86]],\n","\n","       ...,\n","\n","       [[174, 142, 121],\n","        [174, 142, 121],\n","        [174, 142, 121],\n","        ...,\n","        [163, 131, 110],\n","        [163, 131, 110],\n","        [163, 131, 110]],\n","\n","       [[174, 142, 121],\n","        [174, 142, 121],\n","        [175, 143, 122],\n","        ...,\n","        [162, 131, 110],\n","        [162, 131, 110],\n","        [162, 131, 110]],\n","\n","       [[173, 141, 120],\n","        [174, 142, 121],\n","        [175, 143, 122],\n","        ...,\n","        [162, 131, 110],\n","        [162, 131, 110],\n","        [162, 131, 110]]], dtype=uint8)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import skimage\n","pixels = skimage.io.imread('frames/frame_0001.jpg')\n","pixels"]},{"cell_type":"markdown","metadata":{},"source":["### 🔬 Checkpoint Tests 🔬"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["🎉 All Tests Passed! 🎉\n"]}],"source":["## == CHECKPOINT TESTS ==\n","# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n","# - If this cell results in a celebration message, you PASSED all test cases!\n","# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n","tada = \"\\N{PARTY POPPER}\"\n","\n","assert(\"pixels\" in vars())\n","assert(pixels.shape == (360, 640, 3))\n","assert(pixels[0][0][0] == 91)\n","\n","print(f\"{tada} All Tests Passed! {tada}\")"]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"color: #DD3403;\">"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Part 1: Storing Average Pixel Color\n","\n","The **shape** of your data is the `rows` by `columns` by `color values` as 3-dimensional list.  Here's a formatted view of your `pixels` data:\n","\n","```\n","[\n","  [ [91, 83, 80], [91, 83, 80], [91, 83, 80] ], ... ],   # Row #1\n","  [ [91, 83, 80], [91, 83, 80], [91, 83, 80] ], ... ],   # Row #2\n","  ...                                                    # ...\n","]\n","```\n","\n","The current shape of `pixels` is 360 rows by 640 columns by 3 colors (`360` x `640` x `3`).  Each of the three colors represent the three color channels on a screen: red, green, and blue.\n","\n","Using `pixel.mean()`, we find the average color grouping **ALL** the color channels (combining blues and reds and greens together).  Try it out:\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["72.18011863425926"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["pixels.mean()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This value is not very useful.  It is the average of red, green, and blue all lumped together -- it would be far more useful to find the average **red**, average **green**, and average **blue** independently.\n","\n","To do that, we first need to \"flatten\" the list so that we have a list of only color data instead of a list of rows, columns, and then color data.  That means we want our list to look like the following:\n","\n","```\n","[\n","  [ 91, 83, 80 ],    # Pixel #1 color data\n","  [ 91, 83, 80 ],    # Pixel #2 color data\n","  [ 91, 83, 80 ],    # Pixel #3 color data\n","  ...\n","]\n","```\n","\n","### Using `pixels.reshape()`\n","\n","Now that we have the desired shape of the list, the `reshape` function can do the hard work!  We know we want the final shape to be `?`x `3`.  As long as you only have one unknown dimensions, Python allows you to provide a `-1` and it will place all of the data there.\n","\n","That means `pixels.reshape(-1, 3)` will reshape our list to be a single long list of color data.  Let's try out that transformation:"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 91,  83,  80],\n","       [ 91,  83,  80],\n","       [ 91,  83,  80],\n","       ...,\n","       [162, 131, 110],\n","       [162, 131, 110],\n","       [162, 131, 110]], dtype=uint8)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["pixels = pixels.reshape(-1, 3)\n","pixels"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Finally, we want the average value of each element of the list.  To do this, `pixels.mean(axis=0)` finds the average color of each element of our newly formatted list of pixels:"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["array([88.65917535, 67.45620226, 60.4249783 ])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["pixels.mean(axis=0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Puzzle 1.1: Finding the Average Color of One Image\n","\n","Given the output you learned above, write the Python code to store `pixel`'s average red value in `r`, average green value in `g`, and average blue value in `b`:"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["r = pixels.mean(axis=0)[0]\n","g = pixels.mean(axis=0)[1]\n","b = pixels.mean(axis=0)[2]"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["🎉 All Tests Passed! 🎉\n"]}],"source":["## == CHECKPOINT TESTS ==\n","# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n","# - If this cell results in a celebration message, you PASSED all test cases!\n","# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n","tada = \"\\N{PARTY POPPER}\"\n","\n","import math\n","assert(\"r\" in vars())\n","assert(\"g\" in vars())\n","assert(\"b\" in vars())\n","assert(r > 88 and r < 89)\n","assert(g > 67 and g < 68)\n","assert(b > 60 and b < 61)\n","\n","print(f\"{tada} All Tests Passed! {tada}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Puzzle 1.2: Finding the Average Color of All Images\n","\n","The following code loops through every file in the `frames` directory -- this will include `frame_0001.jpg` (like you analyzed already) and also `frame_0002.jpg`, `frame_0003.jpg`, and all 300+ frames!\n","\n","Create a DataFrame where each row is one frame with the following four columns:\n","- `frame`, the filename of the frame\n","- `r`, the average red color of the frame\n","- `g`, the average green color of the frame\n","- `b`, the average blue color of the frame\n","\n","The structure of the code should be nearly **identical to writing a simulation**.  For \"Step 3\" when you would normally simulate a random variable for the real-world event, you should instead use the real world data.  This real world data will be filename `frame`, and the `r`, `g`, and `b` values should be the average color of that frame.\n","\n","- See: https://discovery.cs.illinois.edu/learn/Simulation-and-Distributions/Simple-Simulations-in-Python/"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>frame</th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>frames\\frame_0001.jpg</td>\n","      <td>88.659175</td>\n","      <td>67.456202</td>\n","      <td>60.424978</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>frames\\frame_0002.jpg</td>\n","      <td>88.697865</td>\n","      <td>67.453529</td>\n","      <td>60.475660</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>frames\\frame_0003.jpg</td>\n","      <td>88.028351</td>\n","      <td>66.913845</td>\n","      <td>60.064592</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>frames\\frame_0004.jpg</td>\n","      <td>88.825629</td>\n","      <td>67.340347</td>\n","      <td>60.491645</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>frames\\frame_0005.jpg</td>\n","      <td>88.211714</td>\n","      <td>66.979661</td>\n","      <td>59.983173</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>325</th>\n","      <td>frames\\frame_0326.jpg</td>\n","      <td>7.470391</td>\n","      <td>7.473355</td>\n","      <td>7.479188</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>frames\\frame_0327.jpg</td>\n","      <td>7.469779</td>\n","      <td>7.472743</td>\n","      <td>7.478576</td>\n","    </tr>\n","    <tr>\n","      <th>327</th>\n","      <td>frames\\frame_0328.jpg</td>\n","      <td>7.480234</td>\n","      <td>7.481519</td>\n","      <td>7.487826</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>frames\\frame_0329.jpg</td>\n","      <td>7.480004</td>\n","      <td>7.481289</td>\n","      <td>7.487595</td>\n","    </tr>\n","    <tr>\n","      <th>329</th>\n","      <td>frames\\frame_0330.jpg</td>\n","      <td>4.657478</td>\n","      <td>4.658776</td>\n","      <td>4.665082</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>330 rows × 4 columns</p>\n","</div>"],"text/plain":["                     frame          r          g          b\n","0    frames\\frame_0001.jpg  88.659175  67.456202  60.424978\n","1    frames\\frame_0002.jpg  88.697865  67.453529  60.475660\n","2    frames\\frame_0003.jpg  88.028351  66.913845  60.064592\n","3    frames\\frame_0004.jpg  88.825629  67.340347  60.491645\n","4    frames\\frame_0005.jpg  88.211714  66.979661  59.983173\n","..                     ...        ...        ...        ...\n","325  frames\\frame_0326.jpg   7.470391   7.473355   7.479188\n","326  frames\\frame_0327.jpg   7.469779   7.472743   7.478576\n","327  frames\\frame_0328.jpg   7.480234   7.481519   7.487826\n","328  frames\\frame_0329.jpg   7.480004   7.481289   7.487595\n","329  frames\\frame_0330.jpg   4.657478   4.658776   4.665082\n","\n","[330 rows x 4 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["import glob\n","import os\n","import pandas as pd\n","\n","data = []\n","for frame in glob.glob(os.path.join(\"frames\", \"*.jpg\")): \n","  # `frame`` contains the filename of the frame (ex: \"frames/frame_0001.jpg\").  Use it for `imread` to read the frame image data.\n","  pixels = skimage.io.imread(frame).reshape(-1,3)\n","  r = pixels.mean(axis=0)[0]\n","  g = pixels.mean(axis=0)[1]\n","  b = pixels.mean(axis=0)[2]  \n","  d = {'frame': frame, 'r': r, 'g': g, 'b': b}\n","  data.append(d)\n","\n","df = pd.DataFrame(data)\n","df"]},{"cell_type":"markdown","metadata":{},"source":["### 🔬 Checkpoint Tests 🔬"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["🎉 All Tests Passed! 🎉\n"]}],"source":["## == CHECKPOINT TESTS ==\n","# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n","# - If this cell results in a celebration message, you PASSED all test cases!\n","# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n","tada = \"\\N{PARTY POPPER}\"\n","\n","import math\n","assert(\"df\" in vars())\n","assert(len(df) == 330)\n","assert(\"r\" in df)\n","assert(\"g\" in df)\n","assert(\"b\" in df)\n","assert(\"frame\" in df)\n","assert( abs( df[ df.frame.str.endswith(\"_0001.jpg\") ][\"r\"].sum() - 88 ) < 1 )\n","\n","print(f\"{tada} All Tests Passed! {tada}\")"]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"color: #DD3403;\">"]},{"cell_type":"markdown","metadata":{},"source":["## Part 2: Create a Simple Classifier\n","\n","In the DISCOVERY lecture videos, there are two primary \"scenes\" in the video:\n","\n","1. **\"Office Hours Studio Scene\"**, where Karle and Wade are talking to each other and the audience,\n","\n","2. **\"Notebook Scene\"**, where the notebook is displayed\n","\n","View the `frames` folder on your computer and find **at least three more frames** that are in the \"office hours studio scene\" and **at least three more frames** that are in the \"notebook scene\".  Add the frames you found to the list below:"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# List of at least four office hour frames by the filename's frame number:\n","office_hour_frames = [1, 4, 166, 171]\n","\n","# List of at least four notebook frames by the filename's frame number:\n","notebook_frames = [30, 191, 185, 187]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Observing the Average Colors of Your Frames\n","\n","The following code uses your sample frames to display the average color values for your selected frames.  This information about the average color of the two different type of frames will be useful for you to build the classifier in the next section.\n","\n","You may want to add more frames into your list above to get more data to help build your classifier.  Run the following code to see the average color values:"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["== Office Hour Frames ==\n","                     frame          r          g          b\n","0    frames\\frame_0001.jpg  88.659175  67.456202  60.424978\n","3    frames\\frame_0004.jpg  88.825629  67.340347  60.491645\n","165  frames\\frame_0166.jpg  89.799861  69.913568  61.715846\n","170  frames\\frame_0171.jpg  90.530456  70.301437  62.171632\n","\n","== Notebook Frames ==\n","                     frame           r           g           b\n","29   frames\\frame_0030.jpg  237.225595  236.513451  236.777122\n","184  frames\\frame_0185.jpg  233.223641  232.456962  230.245742\n","186  frames\\frame_0187.jpg  233.127865  232.372739  230.165365\n","190  frames\\frame_0191.jpg  233.117088  232.354644  230.103359\n"]}],"source":["import os\n","\n","print(\"== Office Hour Frames ==\")\n","print( df[ df[\"frame\"].isin( [os.path.join(\"frames\", f\"frame_{frame:04d}.jpg\") for frame in office_hour_frames]) ] )\n","print()\n","print(\"== Notebook Frames ==\")\n","print( df[ df[\"frame\"].isin( [os.path.join(\"frames\", f\"frame_{frame:04d}.jpg\") for frame in notebook_frames]) ] )"]},{"cell_type":"markdown","metadata":{},"source":["### Create Your Classifier Function\n","\n","A **classifier function** is a function that takes data and gives a classification for that data.  Create a new function, `classifyFrame` that receives an `r`, `g`, and `b` value.\n","\n","Using information from your frames above, have the function return the string `\"office hour\"` or `\"notebook\"` based on the values of `r`, `g`, and `b`.\n","\n","**IMPORTANT**: Make sure your classifier can handle **ANY** input -- even frames you have not seen before!  For example, you might decide that you will call a frame an `\"office hour\"` frame if the sum of `r`, `g` and `b` is greater than 100 and otherwise it's a `\"notebook\"` scene."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def classifyFrame(r, g, b):\n","  # Return either \"office hour\" or \"notebook\" based on the values of `r`, `g`, and `b`.\n","  if (r + g + b > 600):\n","    return \"notebook\"\n","  else:\n","    return \"office hour\""]},{"cell_type":"markdown","metadata":{},"source":["### 🔬 Checkpoint Tests 🔬"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["🎉 All Tests Passed! 🎉\n"]}],"source":["## == CHECKPOINT TESTS ==\n","# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n","# - If this cell results in a celebration message, you PASSED all test cases!\n","# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n","tada = \"\\N{PARTY POPPER}\"\n","\n","r = classifyFrame(0, 0, 0)\n","assert(r == \"notebook\" or r == \"office hour\")\n","\n","r = classifyFrame(255, 255, 255)\n","assert(r == \"notebook\" or r == \"office hour\")\n","\n","r = classifyFrame(0, 255, 255)\n","assert(r == \"notebook\" or r == \"office hour\")\n","\n","r = classifyFrame(255, 255, 0)\n","assert(r == \"notebook\" or r == \"office hour\")\n","\n","print(f\"{tada} All Tests Passed! {tada}\")"]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"color: #DD3403;\">"]},{"cell_type":"markdown","metadata":{},"source":["## Part 3: Using Your Classifier!\n","\n","Now that we have a classifier, we should run it on every frame!\n","\n","The following cell runs your `classifyFrame` classifier on every frame and adds a new column `scene` and displayed 20 random rows:"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>frame</th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>scene</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>frames\\frame_0002.jpg</td>\n","      <td>88.697865</td>\n","      <td>67.453529</td>\n","      <td>60.475660</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>186</th>\n","      <td>frames\\frame_0187.jpg</td>\n","      <td>233.127865</td>\n","      <td>232.372739</td>\n","      <td>230.165365</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>319</th>\n","      <td>frames\\frame_0320.jpg</td>\n","      <td>221.227565</td>\n","      <td>71.838433</td>\n","      <td>54.457305</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>109</th>\n","      <td>frames\\frame_0110.jpg</td>\n","      <td>230.717266</td>\n","      <td>230.119089</td>\n","      <td>227.517656</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>140</th>\n","      <td>frames\\frame_0141.jpg</td>\n","      <td>230.853845</td>\n","      <td>229.936962</td>\n","      <td>227.710512</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>272</th>\n","      <td>frames\\frame_0273.jpg</td>\n","      <td>243.548924</td>\n","      <td>242.609227</td>\n","      <td>241.175135</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>115</th>\n","      <td>frames\\frame_0116.jpg</td>\n","      <td>88.151432</td>\n","      <td>68.003542</td>\n","      <td>60.601997</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>114</th>\n","      <td>frames\\frame_0115.jpg</td>\n","      <td>87.702435</td>\n","      <td>67.753620</td>\n","      <td>60.350282</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>248</th>\n","      <td>frames\\frame_0249.jpg</td>\n","      <td>244.143333</td>\n","      <td>243.400534</td>\n","      <td>241.659718</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>139</th>\n","      <td>frames\\frame_0140.jpg</td>\n","      <td>87.663203</td>\n","      <td>67.649766</td>\n","      <td>60.055399</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>210</th>\n","      <td>frames\\frame_0211.jpg</td>\n","      <td>238.529397</td>\n","      <td>237.846072</td>\n","      <td>235.496111</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>frames\\frame_0065.jpg</td>\n","      <td>231.244536</td>\n","      <td>230.689201</td>\n","      <td>230.925812</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>321</th>\n","      <td>frames\\frame_0322.jpg</td>\n","      <td>200.769965</td>\n","      <td>41.149089</td>\n","      <td>18.975074</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>frames\\frame_0126.jpg</td>\n","      <td>87.740946</td>\n","      <td>68.014570</td>\n","      <td>60.462257</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>298</th>\n","      <td>frames\\frame_0299.jpg</td>\n","      <td>89.306185</td>\n","      <td>70.066285</td>\n","      <td>62.480816</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>127</th>\n","      <td>frames\\frame_0128.jpg</td>\n","      <td>87.730820</td>\n","      <td>67.646042</td>\n","      <td>60.164588</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>203</th>\n","      <td>frames\\frame_0204.jpg</td>\n","      <td>238.584375</td>\n","      <td>237.830625</td>\n","      <td>235.545221</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>220</th>\n","      <td>frames\\frame_0221.jpg</td>\n","      <td>244.376549</td>\n","      <td>243.676888</td>\n","      <td>241.910747</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>126</th>\n","      <td>frames\\frame_0127.jpg</td>\n","      <td>87.730642</td>\n","      <td>67.961332</td>\n","      <td>60.376766</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>123</th>\n","      <td>frames\\frame_0124.jpg</td>\n","      <td>88.320039</td>\n","      <td>68.088030</td>\n","      <td>60.619171</td>\n","      <td>office hour</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     frame           r           g           b        scene\n","1    frames\\frame_0002.jpg   88.697865   67.453529   60.475660  office hour\n","186  frames\\frame_0187.jpg  233.127865  232.372739  230.165365     notebook\n","319  frames\\frame_0320.jpg  221.227565   71.838433   54.457305  office hour\n","109  frames\\frame_0110.jpg  230.717266  230.119089  227.517656     notebook\n","140  frames\\frame_0141.jpg  230.853845  229.936962  227.710512     notebook\n","272  frames\\frame_0273.jpg  243.548924  242.609227  241.175135     notebook\n","115  frames\\frame_0116.jpg   88.151432   68.003542   60.601997  office hour\n","114  frames\\frame_0115.jpg   87.702435   67.753620   60.350282  office hour\n","248  frames\\frame_0249.jpg  244.143333  243.400534  241.659718     notebook\n","139  frames\\frame_0140.jpg   87.663203   67.649766   60.055399  office hour\n","210  frames\\frame_0211.jpg  238.529397  237.846072  235.496111     notebook\n","64   frames\\frame_0065.jpg  231.244536  230.689201  230.925812     notebook\n","321  frames\\frame_0322.jpg  200.769965   41.149089   18.975074  office hour\n","125  frames\\frame_0126.jpg   87.740946   68.014570   60.462257  office hour\n","298  frames\\frame_0299.jpg   89.306185   70.066285   62.480816  office hour\n","127  frames\\frame_0128.jpg   87.730820   67.646042   60.164588  office hour\n","203  frames\\frame_0204.jpg  238.584375  237.830625  235.545221     notebook\n","220  frames\\frame_0221.jpg  244.376549  243.676888  241.910747     notebook\n","126  frames\\frame_0127.jpg   87.730642   67.961332   60.376766  office hour\n","123  frames\\frame_0124.jpg   88.320039   68.088030   60.619171  office hour"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["df[\"scene\"] = df.apply(lambda row: classifyFrame(row.r, row.g, row.b), axis=1)\n","df.sample(20)"]},{"cell_type":"markdown","metadata":{},"source":["### 🔬 Checkpoint Tests 🔬"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["🎉 All Tests Passed! 🎉\n"]}],"source":["## == CHECKPOINT TESTS ==\n","# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n","# - If this cell results in a celebration message, you PASSED all test cases!\n","# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n","tada = \"\\N{PARTY POPPER}\"\n","\n","assert(\"scene\" in df)\n","\n","assert(len(df[ df.scene == \"notebook\" ]) > 100), \"There are more than 100 frames that are clearly the notebook.  Make sure your classifier is able to pick up the notebook scene accurately.\"\n","assert(len(df[ df.scene == \"office hour\" ]) > 75), \"There are more than 75 frames that are clearly the office hour set.  Make sure your classifier is able to pick up the office hour set scene accurately.\"\n","assert(len(df[ df.scene == \"notebook\" ]) + len(df[ df.scene == \"office hour\" ]) == len(df)), \"Your classifier should must always identify a scene as either a notebook or office hour.  Make sure your classifier always returns one of those two values.\"\n","\n","assert( len( df[ (df.frame.str.endswith(\"0001.jpg\")) & (df.scene == \"office hour\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0306.jpg\")) & (df.scene == \"office hour\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0081.jpg\")) & (df.scene == \"notebook\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0191.jpg\")) & (df.scene == \"notebook\") ] ) == 1 )\n","\n","print(f\"{tada} All Tests Passed! {tada}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Observing Results\n","\n","In the next 5 cells, we display a frame and you'll run code to check what your classifier classified the frame as being!  Make sure to run the code for each frame:"]},{"cell_type":"markdown","metadata":{},"source":["### Frame #0001: Office Hours"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>frame</th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>scene</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>frames\\frame_0001.jpg</td>\n","      <td>88.659175</td>\n","      <td>67.456202</td>\n","      <td>60.424978</td>\n","      <td>office hour</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   frame          r          g          b        scene\n","0  frames\\frame_0001.jpg  88.659175  67.456202  60.424978  office hour"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["df[ df.frame.str.endswith(\"0001.jpg\") ]"]},{"cell_type":"markdown","metadata":{},"source":["![Frame 0001](frames/frame_0001.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["### Frame #0081: Notebook"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>frame</th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>scene</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>80</th>\n","      <td>frames\\frame_0081.jpg</td>\n","      <td>230.721385</td>\n","      <td>229.915091</td>\n","      <td>230.48303</td>\n","      <td>notebook</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    frame           r           g          b     scene\n","80  frames\\frame_0081.jpg  230.721385  229.915091  230.48303  notebook"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df[ df.frame.str.endswith(\"0081.jpg\") ]"]},{"cell_type":"markdown","metadata":{},"source":["![Frame 0001](frames/frame_0081.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["### Frame #0191: Notebook"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>frame</th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>scene</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>190</th>\n","      <td>frames\\frame_0191.jpg</td>\n","      <td>233.117088</td>\n","      <td>232.354644</td>\n","      <td>230.103359</td>\n","      <td>notebook</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     frame           r           g           b     scene\n","190  frames\\frame_0191.jpg  233.117088  232.354644  230.103359  notebook"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["df[ df.frame.str.endswith(\"0191.jpg\") ]"]},{"cell_type":"markdown","metadata":{},"source":["![Frame 0001](frames/frame_0191.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["### Frame #0306: Office Hours"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>frame</th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>scene</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>305</th>\n","      <td>frames\\frame_0306.jpg</td>\n","      <td>89.403867</td>\n","      <td>70.149223</td>\n","      <td>62.83901</td>\n","      <td>office hour</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     frame          r          g         b        scene\n","305  frames\\frame_0306.jpg  89.403867  70.149223  62.83901  office hour"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["df[ df.frame.str.endswith(\"0306.jpg\") ]"]},{"cell_type":"markdown","metadata":{},"source":["![Frame 0001](frames/frame_0306.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["### Frame #0320: Data Science Duo Logo???\n","\n","What did you classify the DUO logo as?  It's nether one, but we don't have that option!"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>frame</th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>scene</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>319</th>\n","      <td>frames\\frame_0320.jpg</td>\n","      <td>221.227565</td>\n","      <td>71.838433</td>\n","      <td>54.457305</td>\n","      <td>office hour</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     frame           r          g          b        scene\n","319  frames\\frame_0320.jpg  221.227565  71.838433  54.457305  office hour"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["df[ df.frame.str.endswith(\"0320.jpg\") ]"]},{"cell_type":"markdown","metadata":{},"source":["![Frame 0001](frames/frame_0320.jpg)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Frame #328: Video Credits\n","\n","What did you classify the video credits as?  It's another tricky one!\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>frame</th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>scene</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>327</th>\n","      <td>frames\\frame_0328.jpg</td>\n","      <td>7.480234</td>\n","      <td>7.481519</td>\n","      <td>7.487826</td>\n","      <td>office hour</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     frame         r         g         b        scene\n","327  frames\\frame_0328.jpg  7.480234  7.481519  7.487826  office hour"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["df[ df.frame.str.endswith(\"0328.jpg\") ]"]},{"cell_type":"markdown","metadata":{},"source":["![Frame 0328](frames/frame_0328.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"color: #DD3403;\">"]},{"cell_type":"markdown","metadata":{},"source":["## Part 4: Update Your Classifier to Account with an \"Other\" Category\n","\n","Create a second classifier -- `classifyFrame2` -- that returns either `\"notebook\"`, `\"office hour\"` or `\"other\"`.  Your classifier should correctly handle the \"Data Science Duo\" (ex: #0320) frames and the \"Credit\" frames (ex: #0328)."]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["def classifyFrame2(r, g, b):\n","  # Return either \"office hour\", \"notebook\", or \"other\" based on the values of `r`, `g`, and `b`.\n","  if (r + g + b > 600):\n","    return \"notebook\"\n","  elif (r > 200 or r < 20):\n","    return \"other\"\n","  else:\n","    return \"office hour\""]},{"cell_type":"markdown","metadata":{},"source":["## Apply your `classifyFrame2` function\n","\n","Using `classifyFrame2`, this code replaces the value in the column `scene` with your `classifyFrame2` classification function.  The output of this cell shows the last frames of the video, which we expect to be `\"other\"`:"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>frame</th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>scene</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>310</th>\n","      <td>frames\\frame_0311.jpg</td>\n","      <td>89.052721</td>\n","      <td>70.084679</td>\n","      <td>62.528559</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>311</th>\n","      <td>frames\\frame_0312.jpg</td>\n","      <td>89.577539</td>\n","      <td>70.261745</td>\n","      <td>62.894870</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>312</th>\n","      <td>frames\\frame_0313.jpg</td>\n","      <td>89.365169</td>\n","      <td>70.192526</td>\n","      <td>62.526467</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>313</th>\n","      <td>frames\\frame_0314.jpg</td>\n","      <td>89.240360</td>\n","      <td>70.183095</td>\n","      <td>62.777127</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>314</th>\n","      <td>frames\\frame_0315.jpg</td>\n","      <td>89.053277</td>\n","      <td>70.115230</td>\n","      <td>62.639093</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>315</th>\n","      <td>frames\\frame_0316.jpg</td>\n","      <td>227.706259</td>\n","      <td>67.024722</td>\n","      <td>48.608728</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>316</th>\n","      <td>frames\\frame_0317.jpg</td>\n","      <td>233.539870</td>\n","      <td>66.995486</td>\n","      <td>47.766740</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>317</th>\n","      <td>frames\\frame_0318.jpg</td>\n","      <td>227.335317</td>\n","      <td>67.101398</td>\n","      <td>48.556484</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>318</th>\n","      <td>frames\\frame_0319.jpg</td>\n","      <td>221.847739</td>\n","      <td>72.007214</td>\n","      <td>54.584670</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>319</th>\n","      <td>frames\\frame_0320.jpg</td>\n","      <td>221.227565</td>\n","      <td>71.838433</td>\n","      <td>54.457305</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>320</th>\n","      <td>frames\\frame_0321.jpg</td>\n","      <td>218.887899</td>\n","      <td>80.898411</td>\n","      <td>63.118472</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>321</th>\n","      <td>frames\\frame_0322.jpg</td>\n","      <td>200.769965</td>\n","      <td>41.149089</td>\n","      <td>18.975074</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>322</th>\n","      <td>frames\\frame_0323.jpg</td>\n","      <td>201.348303</td>\n","      <td>42.190686</td>\n","      <td>19.636580</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>323</th>\n","      <td>frames\\frame_0324.jpg</td>\n","      <td>201.755673</td>\n","      <td>42.935651</td>\n","      <td>20.674631</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>324</th>\n","      <td>frames\\frame_0325.jpg</td>\n","      <td>0.025247</td>\n","      <td>0.030256</td>\n","      <td>0.038095</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>325</th>\n","      <td>frames\\frame_0326.jpg</td>\n","      <td>7.470391</td>\n","      <td>7.473355</td>\n","      <td>7.479188</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>frames\\frame_0327.jpg</td>\n","      <td>7.469779</td>\n","      <td>7.472743</td>\n","      <td>7.478576</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>327</th>\n","      <td>frames\\frame_0328.jpg</td>\n","      <td>7.480234</td>\n","      <td>7.481519</td>\n","      <td>7.487826</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>frames\\frame_0329.jpg</td>\n","      <td>7.480004</td>\n","      <td>7.481289</td>\n","      <td>7.487595</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>329</th>\n","      <td>frames\\frame_0330.jpg</td>\n","      <td>4.657478</td>\n","      <td>4.658776</td>\n","      <td>4.665082</td>\n","      <td>other</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     frame           r          g          b        scene\n","310  frames\\frame_0311.jpg   89.052721  70.084679  62.528559  office hour\n","311  frames\\frame_0312.jpg   89.577539  70.261745  62.894870  office hour\n","312  frames\\frame_0313.jpg   89.365169  70.192526  62.526467  office hour\n","313  frames\\frame_0314.jpg   89.240360  70.183095  62.777127  office hour\n","314  frames\\frame_0315.jpg   89.053277  70.115230  62.639093  office hour\n","315  frames\\frame_0316.jpg  227.706259  67.024722  48.608728        other\n","316  frames\\frame_0317.jpg  233.539870  66.995486  47.766740        other\n","317  frames\\frame_0318.jpg  227.335317  67.101398  48.556484        other\n","318  frames\\frame_0319.jpg  221.847739  72.007214  54.584670        other\n","319  frames\\frame_0320.jpg  221.227565  71.838433  54.457305        other\n","320  frames\\frame_0321.jpg  218.887899  80.898411  63.118472        other\n","321  frames\\frame_0322.jpg  200.769965  41.149089  18.975074        other\n","322  frames\\frame_0323.jpg  201.348303  42.190686  19.636580        other\n","323  frames\\frame_0324.jpg  201.755673  42.935651  20.674631        other\n","324  frames\\frame_0325.jpg    0.025247   0.030256   0.038095        other\n","325  frames\\frame_0326.jpg    7.470391   7.473355   7.479188        other\n","326  frames\\frame_0327.jpg    7.469779   7.472743   7.478576        other\n","327  frames\\frame_0328.jpg    7.480234   7.481519   7.487826        other\n","328  frames\\frame_0329.jpg    7.480004   7.481289   7.487595        other\n","329  frames\\frame_0330.jpg    4.657478   4.658776   4.665082        other"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["df[\"scene\"] = df.apply(lambda row: classifyFrame2(row.r, row.g, row.b), axis=1)\n","df.tail(20)"]},{"cell_type":"markdown","metadata":{},"source":["### 🔬 Checkpoint Tests 🔬"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["🎉 All Tests Passed! 🎉\n"]}],"source":["## == CHECKPOINT TESTS ==\n","# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n","# - If this cell results in a celebration message, you PASSED all test cases!\n","# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n","tada = \"\\N{PARTY POPPER}\"\n","\n","assert(\"scene\" in df)\n","\n","assert(len(df[ df.scene == \"notebook\" ]) > 100)\n","assert(len(df[ df.scene == \"office hour\" ]) > 75)\n","assert(len(df[ df.scene == \"other\" ]) >= 15)\n","assert(len(df[ df.scene == \"other\" ]) <= 18)   # It's okay to classify the intro screens as \"other\" as well -- but not any others.\n","assert(len(df[ df.scene == \"notebook\" ]) + len(df[ df.scene == \"office hour\" ]) + len(df[ df.scene == \"other\" ]) == len(df))\n","\n","assert( len( df[ (df.frame.str.endswith(\"0001.jpg\")) & (df.scene == \"office hour\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0306.jpg\")) & (df.scene == \"office hour\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0081.jpg\")) & (df.scene == \"notebook\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0191.jpg\")) & (df.scene == \"notebook\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0317.jpg\")) & (df.scene == \"other\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0325.jpg\")) & (df.scene == \"other\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0328.jpg\")) & (df.scene == \"other\") ] ) == 1 )\n","\n","print(f\"{tada} All Tests Passed! {tada}\")"]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"color: #DD3403;\">"]},{"cell_type":"markdown","metadata":{},"source":["## Submission\n","\n","You're almost done!  All you need to do is to commit your lab to GitHub and run the GitHub Actions Grader:\n","\n","1.  ⚠️ **Make certain to save your work.** ⚠️ To do this, go to **File => Save All**\n","\n","2.  After you have saved, exit this notebook and follow the instructions to commit and grade this MicroProject!"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"}}},"nbformat":4,"nbformat_minor":2}
